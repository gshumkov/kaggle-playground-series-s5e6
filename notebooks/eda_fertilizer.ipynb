{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fertilizer Recommendation - Exploratory Data Analysis\n",
    "\n",
    "This notebook performs exploratory data analysis on the fertilizer recommendation dataset. The goal is to predict the appropriate fertilizer based on soil conditions, weather, and crop requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Data Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data info\n",
    "print(\"Dataset Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"\\nStatistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "print(missing[missing > 0] if missing.sum() > 0 else \"No missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fertilizer distribution\n",
    "print(\"Fertilizer Distribution:\")\n",
    "print(df['Fertilizer Name'].value_counts())\n",
    "\n",
    "# Visualize distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "df['Fertilizer Name'].value_counts().plot(kind='bar', color='steelblue')\n",
    "plt.title('Distribution of Fertilizer Types', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Fertilizer Name', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Numerical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features\n",
    "numerical_features = ['Temperature', 'Humidity', 'Moisture', 'Nitrogen', 'Potassium', 'Phosphorous']\n",
    "\n",
    "# Distribution plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(numerical_features):\n",
    "    axes[idx].hist(df[col], bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel(col, fontsize=10)\n",
    "    axes[idx].set_ylabel('Frequency', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots to check for outliers\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(numerical_features):\n",
    "    axes[idx].boxplot(df[col])\n",
    "    axes[idx].set_title(f'Box Plot of {col}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel(col, fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Categorical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soil Type distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Soil Type\n",
    "df['Soil Type'].value_counts().plot(kind='bar', ax=axes[0], color='coral')\n",
    "axes[0].set_title('Distribution of Soil Types', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Soil Type', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Crop Type\n",
    "df['Crop Type'].value_counts().plot(kind='bar', ax=axes[1], color='lightgreen')\n",
    "axes[1].set_title('Distribution of Crop Types', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Crop Type', fontsize=12)\n",
    "axes[1].set_ylabel('Count', fontsize=12)\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for numerical features\n",
    "correlation_matrix = df[numerical_features].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix of Numerical Features', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Analysis by Fertilizer Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NPK values by fertilizer type\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, nutrient in enumerate(['Nitrogen', 'Phosphorous', 'Potassium']):\n",
    "    df.groupby('Fertilizer Name')[nutrient].mean().sort_values().plot(\n",
    "        kind='barh', ax=axes[idx], color='steelblue'\n",
    "    )\n",
    "    axes[idx].set_title(f'Average {nutrient} by Fertilizer', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel(f'{nutrient} Level', fontsize=10)\n",
    "    axes[idx].set_ylabel('Fertilizer Name', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environmental conditions by fertilizer\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, feature in enumerate(['Temperature', 'Humidity', 'Moisture']):\n",
    "    df.groupby('Fertilizer Name')[feature].mean().sort_values().plot(\n",
    "        kind='barh', ax=axes[idx], color='coral'\n",
    "    )\n",
    "    axes[idx].set_title(f'Average {feature} by Fertilizer', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel(f'{feature}', fontsize=10)\n",
    "    axes[idx].set_ylabel('Fertilizer Name', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Pair Plot for Key Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select key features for pair plot\n",
    "key_features = ['Nitrogen', 'Phosphorous', 'Potassium', 'Temperature', 'Fertilizer Name']\n",
    "sns.pairplot(df[key_features], hue='Fertilizer Name', diag_kind='kde', \n",
    "             palette='Set2', plot_kws={'alpha': 0.6})\n",
    "plt.suptitle('Pair Plot of Key Features', y=1.02, fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Relationship between Soil Type, Crop Type and Fertilizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soil Type vs Fertilizer\n",
    "soil_fert = pd.crosstab(df['Soil Type'], df['Fertilizer Name'])\n",
    "plt.figure(figsize=(14, 6))\n",
    "soil_fert.plot(kind='bar', stacked=False, figsize=(14, 6))\n",
    "plt.title('Fertilizer Usage by Soil Type', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Soil Type', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.legend(title='Fertilizer', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop Type vs Fertilizer\n",
    "crop_fert = pd.crosstab(df['Crop Type'], df['Fertilizer Name'])\n",
    "plt.figure(figsize=(14, 6))\n",
    "crop_fert.plot(kind='bar', stacked=False, figsize=(14, 6))\n",
    "plt.title('Fertilizer Usage by Crop Type', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Crop Type', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.legend(title='Fertilizer', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary Statistics by Fertilizer Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group statistics by fertilizer\n",
    "print(\"Average values by Fertilizer Type:\")\n",
    "grouped_stats = df.groupby('Fertilizer Name')[numerical_features].mean()\n",
    "print(grouped_stats.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Classification Algorithm Comparison\n",
    "\n",
    "In this section, we compare different classification algorithms to determine which performs best for fertilizer recommendation. We also evaluate the ability to predict top-3 fertilizers for each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import time\n",
    "\n",
    "# Encode categorical variables\n",
    "le_soil = LabelEncoder()\n",
    "le_crop = LabelEncoder()\n",
    "le_fertilizer = LabelEncoder()\n",
    "\n",
    "df_model = df.copy()\n",
    "df_model['Soil Type Encoded'] = le_soil.fit_transform(df_model['Soil Type'])\n",
    "df_model['Crop Type Encoded'] = le_crop.fit_transform(df_model['Crop Type'])\n",
    "df_model['Fertilizer Encoded'] = le_fertilizer.fit_transform(df_model['Fertilizer Name'])\n",
    "\n",
    "# Prepare features and target\n",
    "feature_cols = ['Temperature', 'Humidity', 'Moisture', 'Nitrogen', \n",
    "                'Potassium', 'Phosphorous', 'Soil Type Encoded', 'Crop Type Encoded']\n",
    "X = df_model[feature_cols]\n",
    "y = df_model['Fertilizer Encoded']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"Number of classes: {len(le_fertilizer.classes_)}\")\n",
    "print(f\"\\nFertilizer classes: {le_fertilizer.classes_.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 Train and Evaluate Multiple Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=20, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "results = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {name}...\")\n",
    "    print('='*60)\n",
    "    \n",
    "    # Train\n",
    "    start_time = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'model': clf,\n",
    "        'accuracy': accuracy,\n",
    "        'train_time': train_time,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Training time: {train_time:.2f} seconds\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training completed for all algorithms!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3 Accuracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare accuracies\n",
    "accuracy_comparison = pd.DataFrame({\n",
    "    'Algorithm': list(results.keys()),\n",
    "    'Accuracy': [results[name]['accuracy'] for name in results.keys()],\n",
    "    'Training Time (s)': [results[name]['train_time'] for name in results.keys()]\n",
    "})\n",
    "\n",
    "accuracy_comparison = accuracy_comparison.sort_values('Accuracy', ascending=False)\n",
    "print(\"\\nAlgorithm Performance Comparison:\")\n",
    "print(accuracy_comparison.to_string(index=False))\n",
    "\n",
    "# Visualize accuracy comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(accuracy_comparison['Algorithm'], accuracy_comparison['Accuracy'], color='skyblue', edgecolor='navy')\n",
    "plt.xlabel('Accuracy', fontsize=12)\n",
    "plt.ylabel('Algorithm', fontsize=12)\n",
    "plt.title('Classification Algorithm Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "plt.xlim([0.8, 1.0])\n",
    "for i, v in enumerate(accuracy_comparison['Accuracy']):\n",
    "    plt.text(v + 0.005, i, f'{v:.4f}', va='center')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.4 Detailed Classification Report for Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model\n",
    "best_model_name = accuracy_comparison.iloc[0]['Algorithm']\n",
    "best_model = results[best_model_name]['model']\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Detailed Report for Best Model: {best_model_name}\")\n",
    "print('='*60)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, best_predictions, target_names=le_fertilizer.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.5 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, best_predictions)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=le_fertilizer.classes_, \n",
    "            yticklabels=le_fertilizer.classes_,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.xlabel('Predicted Fertilizer', fontsize=12)\n",
    "plt.ylabel('Actual Fertilizer', fontsize=12)\n",
    "plt.title(f'Confusion Matrix - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.6 Top-3 Prediction Analysis\n",
    "\n",
    "Since the model may need to predict up to 3 fertilizer recommendations, let's evaluate how well each model performs at providing top-3 predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate top-k accuracy for models that support predict_proba\n",
    "def calculate_topk_accuracy(model, X_test, y_test, k=3):\n",
    "    \"\"\"Calculate top-k accuracy\"\"\"\n",
    "    if not hasattr(model, 'predict_proba'):\n",
    "        return None\n",
    "    \n",
    "    # Get probability predictions\n",
    "    proba = model.predict_proba(X_test)\n",
    "    \n",
    "    # Get top-k predictions for each sample\n",
    "    top_k_predictions = np.argsort(proba, axis=1)[:, -k:]\n",
    "    \n",
    "    # Check if true label is in top-k predictions\n",
    "    correct = 0\n",
    "    for i, true_label in enumerate(y_test):\n",
    "        if true_label in top_k_predictions[i]:\n",
    "            correct += 1\n",
    "    \n",
    "    return correct / len(y_test)\n",
    "\n",
    "# Calculate top-1, top-2, and top-3 accuracy for each model\n",
    "topk_results = []\n",
    "\n",
    "for name, result in results.items():\n",
    "    model = result['model']\n",
    "    top1_acc = result['accuracy']  # This is same as top-1\n",
    "    top2_acc = calculate_topk_accuracy(model, X_test, y_test, k=2)\n",
    "    top3_acc = calculate_topk_accuracy(model, X_test, y_test, k=3)\n",
    "    \n",
    "    if top2_acc is not None:\n",
    "        topk_results.append({\n",
    "            'Algorithm': name,\n",
    "            'Top-1 Accuracy': top1_acc,\n",
    "            'Top-2 Accuracy': top2_acc,\n",
    "            'Top-3 Accuracy': top3_acc\n",
    "        })\n",
    "\n",
    "topk_df = pd.DataFrame(topk_results)\n",
    "topk_df = topk_df.sort_values('Top-3 Accuracy', ascending=False)\n",
    "\n",
    "print(\"\\nTop-K Accuracy Comparison:\")\n",
    "print(topk_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top-k accuracy\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "x = np.arange(len(topk_df))\n",
    "width = 0.25\n",
    "\n",
    "ax.bar(x - width, topk_df['Top-1 Accuracy'], width, label='Top-1', color='steelblue')\n",
    "ax.bar(x, topk_df['Top-2 Accuracy'], width, label='Top-2', color='lightcoral')\n",
    "ax.bar(x + width, topk_df['Top-3 Accuracy'], width, label='Top-3', color='lightgreen')\n",
    "\n",
    "ax.set_xlabel('Algorithm', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Top-K Accuracy Comparison Across Algorithms', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(topk_df['Algorithm'], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.set_ylim([0.8, 1.0])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.7 Example: Top-3 Predictions for Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top-3 predictions for first few test samples\n",
    "def get_top3_predictions(model, X_sample, le_fertilizer):\n",
    "    \"\"\"Get top-3 fertilizer predictions with probabilities\"\"\"\n",
    "    if not hasattr(model, 'predict_proba'):\n",
    "        return None\n",
    "    \n",
    "    proba = model.predict_proba(X_sample)\n",
    "    top3_indices = np.argsort(proba, axis=1)[:, -3:][:, ::-1]  # Get top 3 in descending order\n",
    "    \n",
    "    results = []\n",
    "    for i, indices in enumerate(top3_indices):\n",
    "        predictions = []\n",
    "        for idx in indices:\n",
    "            fertilizer_name = le_fertilizer.classes_[idx]\n",
    "            probability = proba[i, idx]\n",
    "            predictions.append((fertilizer_name, probability))\n",
    "        results.append(predictions)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Get predictions for first 5 test samples\n",
    "sample_size = 5\n",
    "X_sample = X_test.iloc[:sample_size]\n",
    "y_sample = y_test.iloc[:sample_size]\n",
    "\n",
    "print(f\"\\nTop-3 Predictions for {sample_size} Sample Test Cases using {best_model_name}:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top3_preds = get_top3_predictions(best_model, X_sample, le_fertilizer)\n",
    "\n",
    "for i in range(sample_size):\n",
    "    actual_fertilizer = le_fertilizer.classes_[y_sample.iloc[i]]\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(f\"  Actual Fertilizer: {actual_fertilizer}\")\n",
    "    print(f\"  Top-3 Predictions:\")\n",
    "    for rank, (fert_name, prob) in enumerate(top3_preds[i], 1):\n",
    "        marker = \"\u2713\" if fert_name == actual_fertilizer else \" \"\n",
    "        print(f\"    {rank}. {fert_name:30s} (probability: {prob:.4f}) {marker}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.8 Model Comparison Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create comprehensive comparison table\ncomparison_summary = accuracy_comparison.merge(topk_df, on='Algorithm', how='left')\ncomparison_summary = comparison_summary.sort_values('Accuracy', ascending=False)\n\nprint(\"\\n\" + \"=\"*100)\nprint(\"COMPREHENSIVE MODEL COMPARISON SUMMARY\")\nprint(\"=\"*100)\nprint(comparison_summary.to_string(index=False))\n\nprint(\"\\n\" + \"=\"*100)\nprint(\"KEY FINDINGS:\")\nprint(\"=\"*100)\nbest_algo = comparison_summary.iloc[0]\nprint(f\"\\n1. Best Overall Algorithm: {best_algo['Algorithm']}\")\nprint(f\"   - Accuracy: {best_algo['Accuracy']:.4f}\")\nprint(f\"   - Top-3 Accuracy: {best_algo['Top-3 Accuracy']:.4f}\" if pd.notna(best_algo.get('Top-3 Accuracy')) else \"   - Top-3 Accuracy: N/A\")\nprint(f\"   - Training Time: {best_algo['Training Time (s)']:.2f} seconds\")\n\nfastest_algo = comparison_summary.loc[comparison_summary['Training Time (s)'].idxmin()]\nprint(f\"\\n2. Fastest Algorithm: {fastest_algo['Algorithm']}\")\nprint(f\"   - Training Time: {fastest_algo['Training Time (s)']:.2f} seconds\")\nprint(f\"   - Accuracy: {fastest_algo['Accuracy']:.4f}\")\n\nprint(\"\\n3. Top-3 Prediction Capability:\")\nprint(\"   All probability-based models support providing up to 3 fertilizer recommendations\")\nprint(\"   with associated confidence scores, which is valuable for giving users options.\")\n\nprint(\"\\n4. Recommendation:\")\nif best_algo['Accuracy'] > 0.95:\n    print(f\"   Use {best_algo['Algorithm']} for production deployment due to its excellent accuracy.\")\nelse:\n    print(f\"   Consider ensemble methods or feature engineering to improve performance.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 13. Key Insights\n\nBased on the exploratory data analysis:\n\n1. **Dataset Balance**: The dataset is well-balanced across different fertilizer types\n2. **NPK Ratios**: Different fertilizers show distinct NPK (Nitrogen-Phosphorous-Potassium) patterns\n3. **Environmental Factors**: Temperature and humidity ranges vary by fertilizer type\n4. **Soil & Crop Types**: Fertilizer recommendations are relatively uniform across soil and crop types\n5. **Feature Importance**: NPK values appear to be the most distinguishing features for fertilizer classification\n\n## Next Steps\n\n1. Feature engineering (if needed)\n2. Model development and training\n3. Model evaluation and optimization\n4. Deployment with Docker"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}